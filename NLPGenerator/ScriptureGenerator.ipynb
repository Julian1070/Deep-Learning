{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an LSTM built to generate text. It is trained on the bible. It progressively <br>learns to generate language like structures (correct spacing), with mostly English words, <br>but the output remains nonsensical even after longer training.\n",
    "\n",
    "**Overview of model:**\n",
    "- Embedding dimension of 128\n",
    "- 2 LSTM layers\n",
    "- Dropout of 0.25 \n",
    "- Hidden dimension of 512\n",
    "- Batch size of 32\n",
    "- ADAM optimizer \n",
    "    - Learning rate of 0.001\n",
    "- BCE loss\n",
    "\n",
    "**Possible future improvements:** \n",
    "- Randomizing input during training\n",
    "- Tweaking hyperparameters \n",
    "    - Sequence length \n",
    "    - Number of lstm layers \n",
    "    - Dropout rate\n",
    "    - Number of epochs\n",
    "    - etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bible from https://www.kaggle.com/phyred23/bibleverses\n",
    "data = pd.read_csv(\"data/bible_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis 1:1</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis 1:2</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis 1:3</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis 1:4</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis 1:5</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      citation     book  chapter  verse  \\\n",
       "0  Genesis 1:1  Genesis        1      1   \n",
       "1  Genesis 1:2  Genesis        1      2   \n",
       "2  Genesis 1:3  Genesis        1      3   \n",
       "3  Genesis 1:4  Genesis        1      4   \n",
       "4  Genesis 1:5  Genesis        1      5   \n",
       "\n",
       "                                                text  \n",
       "0  In the beginning God created the heaven and th...  \n",
       "1  And the earth was without form, and void; and ...  \n",
       "2  And God said, Let there be light: and there wa...  \n",
       "3  And God saw the light, that it was good: and G...  \n",
       "4  And God called the light Day, and the darkness...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all unique symbols from data and prepping data\n",
    "symbols = set()\n",
    "training_data = \"\"\n",
    "\n",
    "for verse in data[\"text\"]:\n",
    "    # case insensitive\n",
    "    verse = verse.lower()\n",
    "    # line insensitive\n",
    "    verse = verse.replace(\" \\n\", \"\")\n",
    "    verse = verse.replace(\"\\n\", \"\")\n",
    "    verse = verse.strip()\n",
    "    verse = verse + \" \"\n",
    "    training_data += verse \n",
    "    \n",
    "for char in training_data:\n",
    "     symbols.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dictionaries for character to index (vocab) \n",
    "# and index to character (idx_to_char)\n",
    "vocab = dict()\n",
    "\n",
    "for symbol in sorted(list(symbols)):\n",
    "    vocab[symbol] = len(vocab)\n",
    "    \n",
    "idx_to_char = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of sequence used to train the model\n",
    "IN_SEQ_LEN = 64\n",
    "# Length of sequence to be generated\n",
    "OUT_SEQ_LEN = 100\n",
    "# GREED is a measure for how 'greedy' the model is when \n",
    "# generating characters. Used to create a threshold for \n",
    "# sigmoid output by multiplying by max of that output.\n",
    "# Character is then chosen randomly from all characters \n",
    "# that exceed the threshold. For instance, if \"t\" has the\n",
    "# highest sigmoid activation at 0.8 and GREED is set to \n",
    "# 0.8, then the character is chosen randomly (uniform) from \n",
    "# all characters that have an activation of at least 0.64.\n",
    "# First number corresponds to greediness when the last\n",
    "# character was a space (\" \"), second number corresponds\n",
    "# to all other cases. This increases diversity of output.\n",
    "# The first number should be smaller than the second to\n",
    "# increase diversity of words generated while keeping \n",
    "# consistency within words.\n",
    "GREED = (0.5, 0.8)\n",
    "BATCH_SIZE = 32\n",
    "# Length of data for training loop\n",
    "DATA_LEN = len(training_data)\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1\n",
    "# Set USE_CUDE to True when running on GPU.\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model for character level text generation\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab=vocab, \n",
    "        input_len=IN_SEQ_LEN, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        embedding_dim=128, \n",
    "        hidden_dim=512, \n",
    "        lstm_layers=2, \n",
    "        bidirectional=False\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_len = input_len\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.bidir_adjust = 2 if bidirectional else 1\n",
    "        self.output_dim = len(vocab)\n",
    "        \n",
    "        self.embed = nn.Embedding(\n",
    "            len(vocab)+1, \n",
    "            embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            lstm_layers, \n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.hidden = torch.zeros(\n",
    "            lstm_layers, \n",
    "            batch_size, \n",
    "            hidden_dim\n",
    "        )\n",
    "        \n",
    "        self.cellstate = torch.zeros(\n",
    "            lstm_layers, \n",
    "            batch_size, \n",
    "            hidden_dim\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(\n",
    "            self.bidir_adjust*hidden_dim*input_len, \n",
    "            self.output_dim*self.batch_size\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    def reset_cell(self):\n",
    "        self.hidden = torch.zeros(\n",
    "            self.lstm_layers, \n",
    "            self.batch_size, \n",
    "            self.hidden_dim\n",
    "        )\n",
    "        \n",
    "        self.cellstate = torch.zeros(\n",
    "            self.lstm_layers, \n",
    "            self.batch_size, \n",
    "            self.hidden_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x, (self.hidden, self.cellstate) = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x.view(self.batch_size, -1))\n",
    "        x = self.out(x[-1].view(\n",
    "            self.batch_size, \n",
    "            self.output_dim\n",
    "        ))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model, loss function, and optimizer\n",
    "lstm = LSTM()\n",
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    lstm.cuda()\n",
    "# Binary cross entropy loss because the lstm is a classification\n",
    "# model that assigns each character with a probability that it\n",
    "# comes next (correct character = 1, all other characters = 0)\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    lstm.parameters(), \n",
    "    lr=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EPOCH 1 OF 1 ------\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "loss_dict = dict()\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    print(\"------ EPOCH {} OF {} ------\".format(e+1, EPOCHS))\n",
    "    \n",
    "    # Reset cell at the beginning of each epoch\n",
    "    lstm.reset_cell()\n",
    "    \n",
    "    # Looping over the data in batches\n",
    "    for i in range(0, DATA_LEN, BATCH_SIZE):\n",
    "        \n",
    "        if i % 50000 == 0:\n",
    "            print(i/float(DATA_LEN))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Vector of input character sequences\n",
    "        input_vector = torch.tensor([[\n",
    "            vocab.get(char, len(vocab)) \n",
    "            for char in training_data[i+b:i+b+IN_SEQ_LEN]\n",
    "        ] for b in range(BATCH_SIZE)])\n",
    "        \n",
    "        if USE_CUDA and torch.cuda.is_available():\n",
    "            input_vector = input_vector.cuda()\n",
    "        \n",
    "        output_vector = lstm(input_vector)      \n",
    "        \n",
    "        # Creating target vector by looking at the consequent \n",
    "        # characters\n",
    "        target_vector = torch.zeros(output_vector.shape)\n",
    "        for b in range(BATCH_SIZE):\n",
    "            target_vector[b][vocab.get(\n",
    "                training_data[i+b+IN_SEQ_LEN]\n",
    "            )] = 1\n",
    "            \n",
    "        if USE_CUDA and torch.cuda.is_available():\n",
    "            target_vector = target_vector.cuda()\n",
    "        \n",
    "        # Calculating loss and backpropagating\n",
    "        error = loss(output_vector, target_vector)\n",
    "        \n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_dict[(e, int(i/BATCH_SIZE))] = error.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(epoch=0):\n",
    "    losses = [\n",
    "        loss_dict[(epoch, x)] \n",
    "        for x in range(int(DATA_LEN/BATCH_SIZE))\n",
    "    ]\n",
    "    plt.plot(list(range(len(losses))), losses)\n",
    "    plt.title(\"Loss per batch in epoch {}\".format(epoch+1))\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Binary cross-entropy loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss of the model trained on 100,000 characters\n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example(model):\n",
    "    \"\"\"\n",
    "    Takes a model and returns a random sequence of length \n",
    "    IN_SEQ_LEN from the bible (in_seq), a sequence of length \n",
    "    OUT_SEQ_LEN generated by the model (out_seq), and the two \n",
    "    sequences together (full_seq).\n",
    "    \"\"\"\n",
    "    # Getting random sequence from bible\n",
    "    seq_start = np.random.randint(\n",
    "        0, len(training_data)-IN_SEQ_LEN\n",
    "    )\n",
    "    in_seq = training_data[\n",
    "        seq_start:seq_start+IN_SEQ_LEN+BATCH_SIZE-1\n",
    "    ]\n",
    "    out_seq = \"\"\n",
    "    full_seq = in_seq\n",
    "    \n",
    "    # Resetting cell state\n",
    "    model.reset_cell()\n",
    "    \n",
    "    # Initializing greediness depending on last character \n",
    "    # of input\n",
    "    G = GREED[0] if in_seq[-1] == \" \" else GREED[1]\n",
    "    \n",
    "    # Looping over the number of characters to be generated\n",
    "    for i in range(OUT_SEQ_LEN):\n",
    "\n",
    "        # Getting input vector\n",
    "        current_in = torch.tensor([[\n",
    "            vocab.get(char, len(vocab)) \n",
    "            for char in full_seq[i+b:i+b+IN_SEQ_LEN]\n",
    "        ] for b in range(BATCH_SIZE)])\n",
    "\n",
    "        if USE_CUDA and torch.cuda.is_available():\n",
    "            current_in = current_in.cuda()\n",
    "\n",
    "        current_out = model(current_in)\n",
    "        \n",
    "        # Getting options for next character based on \n",
    "        # greediness\n",
    "        options = [[] for b in range(BATCH_SIZE)]\n",
    "        option_idx = (\n",
    "            current_out >= G*current_out.max(\n",
    "                1, keepdim=True)[0]).nonzero()\n",
    "        \n",
    "        for j, k in option_idx:\n",
    "            options[j].append(k)\n",
    "        \n",
    "        # Selecting the next character from options\n",
    "        out_char = \"\".join([idx_to_char[o.item()] \n",
    "                            for o in [np.random.choice(l) \n",
    "                                for l in options]])[-1]\n",
    "        \n",
    "        # Updating greediness based on new last character\n",
    "        G = GREED[0] if out_char == \" \" else GREED[1]\n",
    "        \n",
    "        # Updating sequences\n",
    "        out_seq += out_char\n",
    "        full_seq += out_char\n",
    "\n",
    "    return full_seq, in_seq, out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on 0 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model output is fully random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm0 = LSTM()\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ey took up of the fragments that remained twelve baskets full. and they that had eaten were abo\n",
      "OUTPUT: da-:!|'ko!wwk)n;d|!bbif?dl  'f-vy,|a|hu| !bb-ulbkuopvq)r't:h|r!bos.w!jzihka);ap.cmjf,uvbeowzbez'bnm.\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm0)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on 100 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model outputs the same character over and over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm100 = torch.load(\n",
    "    \"models/lstm100char\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ll cast thee as profane out of the mountain of god: and i will destroy thee, o covering cherub,\n",
      "OUTPUT: ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm100)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on 1,000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model starts learning about spacing, but only uses one other character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1000 = torch.load(\n",
    "    \"models/lstm1000char\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ntiles, i magnify mine office: if by any means i may provoke to emulation them which are my fle\n",
      "OUTPUT:  a a a   a   a   a   a a  a a  a a      a  a       a    a a   a  a    a a   a a  a  a a a  a    a  a\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm1000)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on 10,000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model puts together characters and separates them with spaces. No actual words yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm10000 = torch.load(\n",
    "    \"models/lstm10000char\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: oshua: for i will utterly put out the remembrance of amalek from under heaven. and moses built \n",
      "OUTPUT: edsesio hh e anto nrl ehl ton neldlddl nn t a andr  ee eoet t  l odd o e  eat e lrw sm d don tssd ll\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm10000)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on 100,000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model uses some real words, like \"the\" and \"them\". Spacing improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm100000 = torch.load(\n",
    "    \"models/lstm100000char\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  whose end is to be burned. but, beloved, we are persuaded better things of you, and things tha\n",
      "OUTPUT: themed o e ho the cel tot ald hta te tha thely the them ald flet ahd the thwl  wot  and th ssd ns an\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm100000)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training on full data (>4M characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly English words, correct spacing (i.e. no double space). Somewhat grammatical but mostly nonsensical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1 = torch.load(\n",
    "    \"models/lstm1\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: ll they die. at the mouth of two witnesses, or three witnesses, shall he that is worthy of deat\n",
      "OUTPUT: h his son son all he weal his said with son the saying, and the senter so was came not as the come o\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm1)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training for two epochs on full data (2x >4M characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much changes when adding a second epoch - the output suffers from similar insufficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm2 = torch.load(\n",
    "    \"models/lstm2\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: d the kingdom, and had strengthened himself, he forsook the law of the lord, and all israel wit\n",
      "OUTPUT: h the house house and with unto the llren for the have were him him the with the med and stered him \n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm2)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM after training for three epochs on full data (3x >4M characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(39, 128)\n",
       "  (lstm): LSTM(128, 512, num_layers=2)\n",
       "  (dropout): Dropout(p=0.25)\n",
       "  (linear): Linear(in_features=32768, out_features=1216, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm3 = torch.load(\n",
    "    \"models/lstm3\", \n",
    "    map_location='cpu'\n",
    ")\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: n they journeyed: whether it was by day or by night that the cloud was taken up, they journeyed\n",
      "OUTPUT:  and not the him the saled have god and the said unto the unto the hear and the shall be a the bread\n"
     ]
    }
   ],
   "source": [
    "_, in_seq, out_seq = get_example(lstm3)\n",
    "print(\"INPUT: {}\".format(in_seq))\n",
    "print(\"OUTPUT: {}\".format(out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
